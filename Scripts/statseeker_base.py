import uuid

import requests
import pandas as pd
from datetime import datetime, timedelta
import pytz
import json
import urllib3
import os
import re
import sys
from dotenv import load_dotenv

load_dotenv()

sys.stdout.reconfigure(encoding='utf-8')


urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

SSL_VERIFY = os.environ.get("SSL_CERT_PATH", True)


# API connection details
base_url = 'https://statseeker.emea.fedex.com/api/v2.1/'
user = os.environ.get("STATSEEKER_USERNAME")
password = os.environ.get("STATSEEKER_PASSWORD")

fields = {
    'device': 'id,deviceid,hostname,ipaddress,ping_state',
    'inventory': 'deviceid,serial,model'
}


# URLs
urls = {
    name: f"{base_url}cdt_{name}?fields={fields[name]}&groups=NOC-Turkey&links=none&limit=10000"
    for name in fields
}

# Log ayarlarÄ±
log_directory = "D:/INTRANET/Netinfo/Logs/Latest_Logs"
os.makedirs(log_directory, exist_ok=True)

log_start_date = datetime.now(pytz.timezone("Europe/Istanbul")).strftime("%Y%m%d")
log_file_path = os.path.join(log_directory, f"network_device_inventory_{log_start_date}.log")

STATUS_LOG_FILE = "D:/INTRANET/Netinfo/Logs/Latest_Logs/device_status_changes.json"
ARCHIVE_FOLDER = "D:/INTRANET/Netinfo/Logs/Archived_Logs"
uuid_file = 'D:/INTRANET/Netinfo/Data/UUID_Pool.json'



def reload_uuid_mapping():
    """ UUID dosyasÄ±nÄ± her Ã§aÄŸrÄ±da yeniden yÃ¼kler ve gÃ¼ncellenmiÅŸ veriyi dÃ¶ndÃ¼rÃ¼r """
    if not os.path.exists(uuid_file):
        log_message(f"ğŸ”´ ERROR: UUID Mapping dosyasÄ± bulunamadÄ±: {uuid_file}")
        return {}, []

    try:
        with open(uuid_file, 'r', encoding='utf-8') as f:
            uuid_data = json.load(f)

        uuid_mapping = uuid_data.get("deviceid_uuid_mapping", {})
        available_uuids = uuid_data.get("available_uuids", [])

        log_message(f"âœ… UUID Mapping YÃ¼klendi: {len(uuid_mapping)} cihaz, {len(available_uuids)} boÅŸ UUID")
        return uuid_mapping, available_uuids
    except json.JSONDecodeError:
        log_message(f"ğŸ”´ ERROR: UUID_Pool.json bozuk, yÃ¼klenemedi!")
        return {}, []
    except Exception as e:
        log_message(f"ğŸ”´ ERROR: UUID Mapping yÃ¼klenirken hata oluÅŸtu: {e}")
        return {}, []


def log_message(message):
    """Write log messages to a file (UTF-8 encoded to prevent encoding errors)."""
    global log_start_date
    current_date = datetime.now(pytz.timezone('Europe/Istanbul')).strftime('%Y%m%d')

    if current_date != log_start_date:
        log_start_date = current_date
        global log_file_path
        log_file_path = os.path.join(log_directory, f"network_device_inventory_{current_date}.log")

    timestamp = datetime.now(pytz.timezone('Europe/Istanbul')).strftime('%Y-%m-%d %H:%M:%S')
    log_entry = f"{timestamp} - {message}\n"

    try:
        with open(log_file_path, 'a', encoding='utf-8') as log_file:
            log_file.write(log_entry)
    except Exception as e:
        print(f"ğŸ”´ HATA: Log dosyasÄ±na yazÄ±lÄ±rken hata oluÅŸtu: {e}")


def log_status_change(deviceid, hostname, old_status, new_status, serial):
    """CihazÄ±n durum deÄŸiÅŸikliklerini loglar ve her kayda benzersiz bir log_id ekler."""

    # ğŸ“‚ JSON dosyasÄ±nÄ± oku (varsa)
    if os.path.exists(STATUS_LOG_FILE):
        try:
            with open(STATUS_LOG_FILE, 'r', encoding='utf-8') as f:
                status_logs = json.load(f)
                if not isinstance(status_logs, list):
                    status_logs = []
        except json.JSONDecodeError:
            status_logs = []
    else:
        status_logs = []

    # â³ **Son 24 saat iÃ§inde aynÄ± cihazÄ±n son kaydÄ±nÄ± bul**
    now = datetime.now(pytz.timezone("Europe/Istanbul"))
    last_24_hours = now - timedelta(hours=24)

    last_entry = None
    filtered_logs = [log for log in status_logs if log["deviceid"] == deviceid]

    if filtered_logs:
        last_entry = max(filtered_logs, key=lambda x: datetime.strptime(x["timestamp"], "%Y-%m-%d %H:%M:%S"))

    # **AynÄ± statÃ¼ye tekrar tekrar giriÅŸ yapmamak iÃ§in kontrol**
    if last_entry:
        last_new_status = last_entry["new_status"]

        if last_new_status == "down" and new_status == "down":
            print(f"ğŸ”µ INFO: {hostname} ({deviceid}) zaten DOWN, tekrar eklenmedi.")
            return

        if last_new_status == "up" and new_status == "up":
            print(f"ğŸ”µ INFO: {hostname} ({deviceid}) zaten UP, tekrar eklenmedi.")
            return

    # âœ… **Yeni deÄŸiÅŸiklik loglanacak!**
    new_entry = {
        "log_id": str(uuid.uuid4()),  # âœ¨ Her kayda benzersiz bir ID ekledik
        "timestamp": now.strftime('%Y-%m-%d %H:%M:%S'),
        "deviceid": deviceid,
        "hostname": hostname,
        "serial": serial,
        "old_status": old_status,
        "new_status": new_status,
        "mail_sent": 0  # âœ¨ Yeni kayÄ±t iÃ§in 'mail_sent' varsayÄ±lan olarak 0!
    }
    status_logs.append(new_entry)

    # **JSON dosyasÄ±na yaz**
    try:
        with open(STATUS_LOG_FILE, 'w', encoding='utf-8') as f:
            json.dump(status_logs, f, indent=2)
        print(f"ğŸŸ¢ LOG: {hostname} ({deviceid}) iÃ§in {old_status} â†’ {new_status} kaydedildi. (mail_sent=0)")
    except Exception as e:
        print(f"ğŸ”´ HATA: JSON gÃ¼ncellenirken hata oluÅŸtu: {e}")

def update_status_change(device, previous_data):
    """CihazÄ±n durum deÄŸiÅŸikliklerini kontrol eder ve sadece belirlenen 3 alanÄ± gÃ¼nceller."""
    deviceid = str(device["deviceid"])
    current_status = device["ping_state"].lower() if isinstance(device["ping_state"], str) else "unknown"

    # GeÃ§ersiz veri varsa atla
    if current_status not in ["up", "down"]:
        print(f"âš ï¸ INFO: {device['hostname']} ({deviceid}) iÃ§in geÃ§ersiz durum atlandÄ±: {current_status}")
        return None

    now = datetime.now(pytz.timezone("Europe/Istanbul")).strftime('%d-%m-%Y %H:%M:%S')

    # Ã–nceki durumu belirle
    previous_status = previous_data.get(deviceid, {}).get("ping_state", current_status)
    last_status_check = previous_data.get(deviceid, {}).get("last_status_check", now)
    last_status_change = previous_data.get(deviceid, {}).get("last_status_change", now)

    # **Durum deÄŸiÅŸikliÄŸi var mÄ±?**
    status_changed = previous_status != current_status

    if status_changed:
        print(f"Status Change Detected: {device['hostname']} (ID: {deviceid}) from {previous_status} to {current_status}.")
        serial = device.get("serial", "Unknown")
        log_status_change(deviceid, device["hostname"], previous_status, current_status, device["serial"])

        last_status_change = now  # Durum deÄŸiÅŸtiyse gÃ¼ncelle

    # **DOWN â†’ UP geÃ§iÅŸinde previous_ping_state 'down' olarak iÅŸaretlenecek**
    previous_ping_state = "down" if previous_status == "down" and current_status == "up" else previous_status

    return {
        "previous_ping_state": previous_ping_state,
        "last_status_check": now,
        "last_status_change": last_status_change
    }



def archive_status_logs():
    """Cihaz durum deÄŸiÅŸikliklerini haftalÄ±k olarak arÅŸivler."""

    # EÄŸer arÅŸiv klasÃ¶rÃ¼ yoksa oluÅŸtur
    os.makedirs(ARCHIVE_FOLDER, exist_ok=True)

    if not os.path.exists(STATUS_LOG_FILE):
        log_message("ğŸ”´ LOG: Status log dosyasÄ± bulunamadÄ±, arÅŸivleme yapÄ±lmadÄ±.")
        return

    # Mevcut deÄŸiÅŸiklikleri oku
    try:
        with open(STATUS_LOG_FILE, 'r') as f:
            status_changes = json.load(f)
            if not isinstance(status_changes, list):
                status_changes = []
    except json.JSONDecodeError:
        status_changes = []

    if not status_changes:
        log_message("ğŸ”´ LOG: Status log boÅŸ, arÅŸivleme yapÄ±lmadÄ±.")
        return

    # **Tarih damgalÄ± arÅŸiv dosyasÄ±nÄ±n adÄ±nÄ± oluÅŸtur**
    timestamp = datetime.now(pytz.timezone("Europe/Istanbul")).strftime('%Y-%m-%d')
    archive_file = os.path.join(ARCHIVE_FOLDER, f"device_status_archive_{timestamp}.json")

    # **ArÅŸiv dosyasÄ±na yaz**
    try:
        with open(archive_file, 'w', encoding='utf-8') as f:
            json.dump(status_changes, f, indent=2)
        log_message(f"ğŸŸ¢ LOG: Cihaz durum deÄŸiÅŸiklikleri arÅŸivlendi â†’ {archive_file}")
    except Exception as e:
        log_message(f"ğŸ”´ HATA: ArÅŸivleme sÄ±rasÄ±nda hata oluÅŸtu: {e}")


def fetch_data(url):
    """Fetch data from API - Direct connection without proxy."""
    try:
        log_message(f"ğŸ”§ BaÄŸlantÄ± kuruluyor...")

        response = requests.get(
            url,
            auth=(user, password),
            verify=SSL_VERIFY,
            timeout=60,
              # Proxy kullanma - direkt baÄŸlantÄ±
        )

        if response.status_code == 200:
            log_message(f"âœ… SUCCESS: BaÄŸlantÄ± baÅŸarÄ±lÄ± - {url}")
            return response.json()
        else:
            log_message(f"âŒ ERROR {response.status_code}: {url}")
            return None

    except requests.exceptions.RequestException as e:
        log_message(f"âŒ FAILED: {url} â†’ {e}")
        return None


# NOC-Turkey grubuna Ã¶zgÃ¼ debug fonksiyonlarÄ±

def debug_noc_turkey_devices():
    """NOC-Turkey grubundaki cihazlarÄ± detaylÄ± analiz eder"""
    print("=" * 80)
    print("ğŸ‡¹ğŸ‡· NOC-TURKEY GRUP ANALÄ°ZÄ°")
    print("=" * 80)

    # 1. Grup bilgilerini kontrol et
    group_url = f"{base_url}cdt_group?fields=id,name,description&links=none&limit=1000"
    try:
        response = requests.get(group_url, auth=(user, password), verify=SSL_VERIFY, timeout=60)
        if response.status_code == 200:
            data = response.json()
            if 'data' in data and 'objects' in data['data'] and data['data']['objects']:
                groups = data['data']['objects'][0]['data']
                turkey_groups = [g for g in groups if
                                 'turkey' in g.get('name', '').lower() or 'noc' in g.get('name', '').lower()]
                print(f"ğŸ“Š Toplam grup sayÄ±sÄ±: {len(groups)}")
                print("ğŸ‡¹ğŸ‡· TÃ¼rkiye ile ilgili gruplar:")
                for group in turkey_groups:
                    print(f"   - {group.get('name', 'N/A')} (ID: {group.get('id', 'N/A')})")
        else:
            print(f"âŒ Grup bilgileri alÄ±namadÄ±: HTTP {response.status_code}")
    except Exception as e:
        print(f"âŒ Grup sorgusu hatasÄ±: {e}")

    # 2. Son 30 gÃ¼n iÃ§inde eklenen cihazlarÄ± kontrol et
    print(f"\nğŸ“… SON 30 GÃœN Ä°Ã‡Ä°NDE EKLENMÄ°Å CÄ°HAZLAR:")
    recent_device_url = f"{base_url}cdt_device?fields=id,deviceid,hostname,ipaddress,ping_state,sysObjectID,sysName,sysUpTime,dateAdded&groups=NOC-Turkey&links=none&limit=10000"

    try:
        response = requests.get(recent_device_url, auth=(user, password), verify=SSL_VERIFY, timeout=60)
        if response.status_code == 200:
            data = response.json()
            if 'data' in data and 'objects' in data['data'] and data['data']['objects']:
                devices = data['data']['objects'][0]['data']

                # Tarih filtreleme
                from datetime import datetime, timedelta

                thirty_days_ago = datetime.now() - timedelta(days=30)

                recent_devices = []
                for device in devices:
                    date_added = device.get('dateAdded')
                    if date_added:
                        try:
                            # Tarih formatÄ±nÄ± parse et (Statseeker formatÄ± genelde UNIX timestamp)
                            if isinstance(date_added, (int, float)):
                                device_date = datetime.fromtimestamp(date_added)
                            elif isinstance(date_added, str):
                                device_date = datetime.strptime(date_added, '%Y-%m-%d %H:%M:%S')
                            else:
                                continue

                            if device_date >= thirty_days_ago:
                                recent_devices.append({
                                    'hostname': device.get('hostname', 'N/A'),
                                    'deviceid': device.get('deviceid', 'N/A'),
                                    'ipaddress': device.get('ipaddress', 'N/A'),
                                    'dateAdded': device_date.strftime('%Y-%m-%d %H:%M:%S')
                                })
                        except Exception as e:
                            print(f"   âš ï¸ Tarih parse hatasÄ±: {device.get('hostname')} - {e}")

                print(f"ğŸ“ˆ Son 30 gÃ¼n iÃ§inde eklenen cihaz sayÄ±sÄ±: {len(recent_devices)}")
                for device in recent_devices[-10:]:  # Son 10'unu gÃ¶ster
                    print(f"   ğŸ†• {device['hostname']} ({device['ipaddress']}) - {device['dateAdded']}")
            else:
                print("âŒ Cihaz verileri alÄ±namadÄ± - veri yapÄ±sÄ± beklenmedik")
        else:
            print(f"âŒ Recent devices sorgusu baÅŸarÄ±sÄ±z: HTTP {response.status_code}")
    except Exception as e:
        print(f"âŒ Recent devices hatasÄ±: {e}")


def debug_device_inventory_mismatch():
    """Device ve Inventory arasÄ±ndaki uyumsuzluklarÄ± kontrol eder"""
    print(f"\nğŸ”— DEVICE-INVENTORY UYUMSUZLUK ANALÄ°ZÄ°:")

    data_frames = {}

    for name, url in urls.items():
        try:
            response = requests.get(url, auth=(user, password), verify=SSL_VERIFY, timeout=60)
            if response.status_code == 200:
                data = response.json()
                df = process_data(data)
                data_frames[name] = df
                print(f"âœ… {name}: {len(df)} kayÄ±t")
            else:
                print(f"âŒ {name}: HTTP {response.status_code}")
                return
        except Exception as e:
            print(f"âŒ {name}: {e}")
            return

    if 'device' in data_frames and 'inventory' in data_frames:
        device_df = data_frames['device']
        inventory_df = data_frames['inventory']

        print(f"\nğŸ“Š Device DataFrame: {len(device_df)} kayÄ±t")
        print(f"ğŸ“Š Inventory DataFrame: {len(inventory_df)} kayÄ±t")

        # Device'da olan ama inventory'de olmayan deviceid'ler
        device_ids = set(device_df['deviceid'].astype(str))
        inventory_ids = set(inventory_df['deviceid'].astype(str))

        missing_in_inventory = device_ids - inventory_ids
        missing_in_device = inventory_ids - device_ids

        print(f"âŒ Device'da var, Inventory'de yok: {len(missing_in_inventory)} cihaz")
        print(f"âŒ Inventory'de var, Device'da yok: {len(missing_in_device)} cihaz")

        if missing_in_inventory:
            print("ğŸ” Device'da var ama Inventory'de olmayan cihazlar:")
            for device_id in list(missing_in_inventory)[:10]:  # Ä°lk 10'unu gÃ¶ster
                device_info = device_df[device_df['deviceid'].astype(str) == device_id].iloc[0]
                print(f"   - {device_info['hostname']} (ID: {device_id})")

        # Merge iÅŸlemi sonucu
        merged = device_df.merge(inventory_df, on='deviceid', how='left')
        print(f"\nğŸ”— Merge sonrasÄ±: {len(merged)} kayÄ±t")

        # Model bilgisi olmayan cihazlarÄ± say
        no_model = merged['model'].isnull().sum()
        print(f"ğŸ“„ Model bilgisi olmayan cihaz sayÄ±sÄ±: {no_model}")


def debug_model_types():
    """Hangi model tÃ¼rlerinin Unknown olarak iÅŸaretlendiÄŸini kontrol eder"""
    print(f"\nğŸ” MODEL TÄ°PLERÄ° ANALÄ°ZÄ°:")

    # Inventory verisini al
    inventory_url = urls['inventory']
    try:
        response = requests.get(inventory_url, auth=(user, password), verify=SSL_VERIFY, timeout=60)
        if response.status_code == 200:
            data = response.json()
            df = process_data(data)

            if not df.empty and 'model' in df.columns:
                # Model daÄŸÄ±lÄ±mÄ±nÄ± analiz et
                model_counts = df['model'].value_counts()
                print(f"ğŸ“Š Toplam unique model sayÄ±sÄ±: {len(model_counts)}")
                print(f"ğŸ“Š Toplam cihaz sayÄ±sÄ±: {len(df)}")

                # Device type'larÄ± kontrol et
                df['device_type'] = df['model'].apply(determine_device_type)
                device_type_counts = df['device_type'].value_counts()
                print(f"\nğŸ“ˆ Device Type DaÄŸÄ±lÄ±mÄ±:")
                for dtype, count in device_type_counts.items():
                    print(f"   {dtype}: {count} cihaz")

                # Unknown olanlarÄ± detaylandÄ±r
                unknown_models = df[df['device_type'] == 'Unknown']['model'].value_counts()
                print(f"\nâ“ UNKNOWN olarak iÅŸaretlenen modeller:")
                for model, count in unknown_models.head(20).items():
                    print(f"   {model}: {count} cihaz")

        else:
            print(f"âŒ Inventory verisi alÄ±namadÄ±: HTTP {response.status_code}")
    except Exception as e:
        print(f"âŒ Model analiz hatasÄ±: {e}")


# Bu fonksiyonlarÄ± update_data() fonksiyonundan Ã–NCE ekleyin:

def debug_uuid_assignment(merged_data, uuid_mapping):
    """UUID atama sÃ¼recini detaylÄ± debug eder"""
    print("=" * 80)
    print("ğŸ†” UUID ATAMA SÃœRECÄ° DEBUG")
    print("=" * 80)

    current_device_ids = set(str(device["deviceid"]) for _, device in merged_data.iterrows())
    mapped_device_ids = set(uuid_mapping.keys())

    print(f"ğŸ“Š Mevcut cihaz sayÄ±sÄ± (merged_data): {len(current_device_ids)}")
    print(f"ğŸ“Š UUID mapping'de kayÄ±tlÄ± cihaz: {len(mapped_device_ids)}")

    # Yeni cihazlar (mapping'de olmayan)
    new_devices = current_device_ids - mapped_device_ids
    print(f"ğŸ†• Yeni cihaz sayÄ±sÄ± (UUID alacak): {len(new_devices)}")

    if new_devices:
        print("ğŸ†• Yeni cihazlar:")
        for device_id in list(new_devices)[:10]:  # Ä°lk 10'unu gÃ¶ster
            device_info = merged_data[merged_data['deviceid'].astype(str) == device_id].iloc[0]
            print(f"   - {device_info['hostname']} (ID: {device_id})")

    # Mapping'de olan ama artÄ±k sistemde olmayan cihazlar
    removed_devices = mapped_device_ids - current_device_ids
    print(f"âŒ Sistemden Ã§Ä±karÄ±lan cihaz sayÄ±sÄ±: {len(removed_devices)}")

    if removed_devices:
        print("âŒ Sistemden Ã§Ä±karÄ±lan cihazlar (UUID'leri geri alÄ±nabilir):")
        for device_id in list(removed_devices)[:10]:
            uuid_val = uuid_mapping.get(device_id, 'N/A')
            print(f"   - Device ID: {device_id}, UUID: {uuid_val}")

    print("=" * 80)
    return new_devices, removed_devices


def reclaim_unused_uuids(uuid_mapping, available_uuids, merged_data):
    """ArtÄ±k kullanÄ±lmayan UUID'leri geri al"""
    current_device_ids = set(str(device["deviceid"]) for _, device in merged_data.iterrows())
    mapped_device_ids = set(uuid_mapping.keys())

    # Sistemde artÄ±k olmayan cihazlarÄ±n UUID'lerini geri al
    removed_devices = mapped_device_ids - current_device_ids
    reclaimed_count = 0

    if removed_devices:
        print(f"ğŸ”„ {len(removed_devices)} cihazÄ±n UUID'si geri alÄ±nacak...")

        for device_id in removed_devices:
            if device_id in uuid_mapping:
                reclaimed_uuid = uuid_mapping.pop(device_id)
                available_uuids.append(reclaimed_uuid)
                reclaimed_count += 1
                log_message(f"â™»ï¸ UUID geri alÄ±ndÄ±: Device {device_id} â†’ UUID {reclaimed_uuid}")

    print(f"â™»ï¸ Toplam {reclaimed_count} UUID geri alÄ±ndÄ±")
    return reclaimed_count


# Åimdi dÃ¼zeltilmiÅŸ update_data fonksiyonu:
def update_data():
    """Fetch and process data, updating status change information."""
    json_file = 'D:/INTRANET/Netinfo/Data/network_device_inventory.json'

    previous_data = load_previous_data()  # Bu fonksiyon zaten kodunuzda var
    uuid_mapping, available_uuids = load_uuid_mapping()  # Bu da zaten var
    data_frames = {}

    for name, url in urls.items():
        log_message(f"Fetching {name} data...")
        data = fetch_data(url)
        if data:
            df = process_data(data)
            data_frames[name] = df
        else:
            log_message(f"âŒ {name} verisi API'den Ã§ekilemedi!")

    if 'device' in data_frames and 'inventory' in data_frames:
        merged_data = data_frames['device'].merge(data_frames['inventory'], on='deviceid', how='left')

        merged_data['device_type'] = merged_data['model'].apply(determine_device_type)
        merged_data = merged_data[merged_data['device_type'] != 'Unknown']
        merged_data['ping_state'] = merged_data['ping_state'].astype(str).str.lower()
        merged_data = merged_data[merged_data['hostname'].notnull() & merged_data['deviceid'].notnull()]

        # ğŸ”¹ **UUID Debug ve Temizleme**
        new_devices_set, removed_devices_set = debug_uuid_assignment(merged_data, uuid_mapping)

        # KullanÄ±lmayan UUID'leri geri al
        reclaimed_count = reclaim_unused_uuids(uuid_mapping, available_uuids, merged_data)

        if reclaimed_count > 0:
            log_message(f"â™»ï¸ {reclaimed_count} UUID geri alÄ±ndÄ±, available pool: {len(available_uuids)}")

        # Location ve city bilgilerini ekle (zaten kodunuzda var)
        try:
            merged_data['location'] = merged_data.apply(
                lambda row: extract_location(row['hostname'], row['deviceid']),
                axis=1
            )
        except Exception as e:
            log_message(f"âŒ HATA: location sÃ¼tunu oluÅŸturulurken hata: {e}")
            return

        station_mapping = station_info()
        if not station_mapping:
            log_message("âŒ ERROR: Station info mapping is empty! Check station-info.json")

        try:
            merged_data['city'] = merged_data['location'].map(lambda x: station_mapping.get(x, 'Unknown'))
        except Exception as e:
            log_message(f"âŒ HATA: 'city' sÃ¼tunu oluÅŸturulÃ¼rken hata: {e}")
            return

        # ğŸ”¹ **UUID Atama - Ä°yileÅŸtirilmiÅŸ**
        newly_assigned_uuids = set()
        uuid_assignment_count = 0

        print(f"\nğŸ†” UUID ATAMA BAÅLADI:")
        print(f"Available UUID pool: {len(available_uuids)}")

        for index, row in merged_data.iterrows():
            deviceid = str(row["deviceid"])

            if deviceid not in uuid_mapping:
                if available_uuids:
                    assigned_uuid = available_uuids.pop(0)
                    uuid_mapping[deviceid] = assigned_uuid
                    newly_assigned_uuids.add(assigned_uuid)
                    uuid_assignment_count += 1
                    merged_data.at[index, 'uuid'] = assigned_uuid
                    log_message(f"ğŸ†• UUID atandÄ±: {row['hostname']} ({deviceid}) â†’ {assigned_uuid}")
                else:
                    assigned_uuid = "UUID_NOT_ASSIGNED"
                    merged_data.at[index, 'uuid'] = assigned_uuid
                    log_message(
                        f"âš ï¸ WARNING: UUID havuzu boÅŸ! {row['hostname']} ({deviceid}) iÃ§in UUID atamasÄ± yapÄ±lamadÄ±.")
            else:
                # Mevcut UUID'yi kullan
                existing_uuid = uuid_mapping[deviceid]
                merged_data.at[index, 'uuid'] = existing_uuid

        print(f"âœ… UUID atama tamamlandÄ±: {uuid_assignment_count} yeni atama")

        merged_data = filter_and_group_devices(merged_data)

        updated_devices = []
        new_devices = []

        for device in merged_data.to_dict(orient='records'):
            status_update = update_status_change(device, previous_data)

            updated_device = {
                "id": device["deviceid"],
                "deviceid": device["deviceid"],
                "hostname": device["hostname"],
                "ipaddress": device["ipaddress"],
                "ping_state": device["ping_state"],
                "serial": device.get("serial", ""),
                "model": device.get("model", ""),
                "device_type": determine_device_type(device.get("model", "")),
                "location": extract_location(device["hostname"], device["deviceid"]),
                "city": station_mapping.get(extract_location(device["hostname"], device["deviceid"]), "Unknown"),
                "uuid": device.get("uuid", "UNKNOWN"),
            }

            if status_update:
                updated_device.update(status_update)

            updated_devices.append(updated_device)

            if str(device["deviceid"]) not in previous_data:
                new_devices.append(device)

        # JSON Ã§Ä±ktÄ±sÄ± kaydÄ±
        with open(json_file, 'w', encoding='utf-8') as f:
            json.dump(updated_devices, f, indent=2)

        log_message(f"ğŸŸ¢ LOG: {len(updated_devices)} cihaz verisi gÃ¼ncellendi â†’ {json_file}")

        # Yeni cihaz bildirimi
        if new_devices:
            log_message(f"ğŸ†• {len(new_devices)} yeni cihaz tespit edildi!")
            for new_device in new_devices[:5]:  # Ä°lk 5'ini logla
                log_message(f"   ğŸ†• Yeni cihaz: {new_device['hostname']}")

        # UUID dosyasÄ±nÄ± gÃ¼ncelle
        remaining_uuids = [uuid for uuid in available_uuids if uuid not in newly_assigned_uuids]
        uuid_data = {"deviceid_uuid_mapping": uuid_mapping, "available_uuids": remaining_uuids}
        uuid_file = 'D:/INTRANET/Netinfo/Data/UUID_Pool.json'
        with open(uuid_file, 'w', encoding='utf-8') as f:
            json.dump(uuid_data, f, indent=2)

        log_message(f"ğŸŸ¢ UUID verisi gÃ¼ncellendi â†’ {uuid_file} (Pool: {len(remaining_uuids)})")
        log_message(f"Update complete. Checked {len(merged_data)} devices.")

    else:
        print("âŒ HATA: Device veya Inventory verisi eksik!")
        if 'device' not in data_frames:
            print("   - Device verisi yok!")
        if 'inventory' not in data_frames:
            print("   - Inventory verisi yok!")




def process_data(data):
    """Convert JSON data to Pandas DataFrame."""
    if 'data' in data and 'objects' in data['data']:
        objects = data['data']['objects']
        if objects and isinstance(objects, list) and 'data' in objects[0]:
            return pd.DataFrame(objects[0]['data'])
    log_message("Unexpected data structure")
    return pd.DataFrame()

def determine_device_type(model):
    """Determine the device type based on the model."""
    if not isinstance(model, str):
        return "Unknown"

    SWITCH_MODELS = ["C9300", "WS-C2960X", "WS-C3850", "C9500", "C9300L"]
    ROUTER_MODELS = ["ISR4351", "ISR4451", "8300"]

    if any(sw in model for sw in SWITCH_MODELS):
        return "Switch"
    elif any(rt in model for rt in ROUTER_MODELS):
        return "Router"
    return "Unknown"

def load_previous_data():
    """Ã–nceki cihaz verilerini JSON'dan yÃ¼kler ve hatalarÄ± engeller."""
    previous_data_file = 'D:/INTRANET/Netinfo/Data/network_device_inventory.json'
    if os.path.exists(previous_data_file):
        try:
            with open(previous_data_file, 'r', encoding='utf-8') as f:
                return {str(d['deviceid']): d for d in json.load(f)}
        except json.JSONDecodeError:
            log_message("ğŸ”´ ERROR: JSON dosyasÄ± bozuk, sÄ±fÄ±rdan baÅŸlatÄ±lÄ±yor!")
            return {}
    return {}


def load_uuid_mapping():
    """ UUID Mapping dosyasÄ±nÄ± gÃ¼venli modda yÃ¼kler. """
    uuid_file = 'D:/INTRANET/Netinfo/Data/UUID_Pool.json'

    if not os.path.exists(uuid_file):
        log_message(f"ğŸ”´ ERROR: UUID Mapping dosyasÄ± bulunamadÄ±: {uuid_file}")
        return {}, []

    try:
        with open(uuid_file, 'r', encoding='utf-8') as f:
            uuid_data = json.load(f)

        uuid_mapping = uuid_data.get("deviceid_uuid_mapping", {})
        available_uuids = uuid_data.get("available_uuids", [])

        log_message(f"âœ… UUID Mapping YÃ¼klendi: {len(uuid_mapping)} cihaz, {len(available_uuids)} boÅŸ UUID")
        return uuid_mapping, available_uuids
    except json.JSONDecodeError:
        log_message(f"ğŸ”´ ERROR: UUID_Pool.json bozuk, yÃ¼klenemedi!")
        return {}, []
    except Exception as e:
        log_message(f"ğŸ”´ ERROR: UUID Mapping yÃ¼klenirken hata oluÅŸtu: {e}")
        return {}, []



def assign_uuid(deviceid, uuid_mapping, available_uuids):
    """Cihaza UUID atar, sadece Ã¶nceden tanÄ±mlanmÄ±ÅŸ boÅŸ UUID'lerden seÃ§er. Yeni UUID oluÅŸturmaz."""
    deviceid_str = str(deviceid)

    if deviceid_str in uuid_mapping:
        return uuid_mapping[deviceid_str]  # EÄŸer zaten atanmÄ±ÅŸ bir UUID varsa, deÄŸiÅŸtirme.

    if available_uuids:
        new_uuid = available_uuids.pop(0)  # Ä°lk boÅŸ UUID'yi al
        uuid_mapping[deviceid_str] = new_uuid
        log_message(f"ğŸ†• Yeni UUID atandÄ±: {deviceid} â†’ {new_uuid}")
        return new_uuid

    log_message(f"âš ï¸ WARNING: UUID havuzunda boÅŸ UUID kalmadÄ±! {deviceid} iÃ§in UUID atamasÄ± yapÄ±lamadÄ±.")
    return "UUID_NOT_ASSIGNED"



def save_current_data(devices):
    """Cihaz verilerini gÃ¼nceller ve JSON dosyasÄ±na yazar."""
    json_file = 'D:/INTRANET/Netinfo/Data/network_device_inventory.json'

    try:
        with open(json_file, 'w', encoding='utf-8') as f:
            json.dump(devices, f, indent=2)
        log_message(f"ğŸŸ¢ LOG: Cihaz verileri gÃ¼ncellendi â†’ {json_file}")
    except Exception as e:
        log_message(f"ğŸ”´ HATA: JSON dosyasÄ± kaydedilirken hata oluÅŸtu: {e}")


def extract_location(hostname, deviceid=None):
    """Hostname iÃ§inden lokasyon kodunu Ã§Ä±kartÄ±r. GeÃ§ersiz durumlarda 'Unknown' dÃ¶ner ve log yazar."""
    if not hostname or not isinstance(hostname, str):
        log_message(f"âš ï¸ WARN: extract_location - geÃ§ersiz hostname ({hostname}) tespit edildi. deviceid: {deviceid}")
        return 'Unknown'
    try:
        match = re.search(r'Tr([A-Za-z0-9]+?)(?=csw|sw|ttr)', hostname, re.IGNORECASE)
        return match.group(1) if match else 'Unknown'
    except Exception as e:
        log_message(f"âš ï¸ ERROR: extract_location - exception. hostname={hostname}, deviceid={deviceid} â†’ {e}")
        return 'Unknown'




def filter_and_group_devices(df):
    """Ã‡ift kayÄ±tlarÄ± engelleyen ve sadece stack baÄŸlÄ± cihazlarÄ± ayrÄ± tutan fonksiyon."""
    stack_devices = df[df['model'].str.contains("STACK", na=False, case=False)]

    df = df[~df['model'].str.contains("STACK", na=False, case=False)]
    df = df.sort_values(by=['deviceid', 'serial']).drop_duplicates(subset=['deviceid'], keep='first')

    return pd.concat([df, stack_devices])

def station_info():
    """Load station information from station-info.json and map code/alternate_code to town."""
    station_file = 'D:/INTRANET/Netinfo/Data/station-info.json'
    if not os.path.exists(station_file):
        log_message(f"Station info file not found: {station_file}")
        return {}

    try:
        with open(station_file, 'r') as f:
            station_data = json.load(f)

        log_message(f"Station info loaded successfully with {len(station_data)} records.")

        # code ve alternate_code'dan town'a eÅŸleÅŸtirme yap
        code_mapping = {}
        for entry in station_data:
            town = entry.get('town', 'Unknown')
            if 'code' in entry:
                code_mapping[entry['code']] = town
            if 'alternate_code' in entry:
                code_mapping[entry['alternate_code']] = town

        return code_mapping
    except Exception as e:
        log_message(f"Error loading station info: {e}")
        return {}

def update_data():
    """Fetch and process data, updating status change information."""
    json_file = 'D:/INTRANET/Netinfo/Data/network_device_inventory.json'

    previous_data = load_previous_data()
    uuid_mapping, available_uuids = load_uuid_mapping()  # UUID listesi yÃ¼klendi
    data_frames = {}

    for name, url in urls.items():
        log_message(f"Fetching {name} data...")
        data = fetch_data(url)
        if data:
            df = process_data(data)
            data_frames[name] = df
        else:
            log_message(f"âŒ {name} verisi API'den Ã§ekilemedi!")

    if 'device' in data_frames and 'inventory' in data_frames:
        merged_data = data_frames['device'].merge(data_frames['inventory'], on='deviceid', how='left')

        merged_data['device_type'] = merged_data['model'].apply(determine_device_type)
        merged_data = merged_data[merged_data['device_type'] != 'Unknown']
        merged_data['ping_state'] = merged_data['ping_state'].astype(str).str.lower()
        merged_data = merged_data[merged_data['hostname'].notnull() & merged_data['deviceid'].notnull()]

        # ğŸ”¹ hostname'den 'location' sÃ¼tunu Ã¼retimi (korumalÄ±)
        try:
            merged_data['location'] = merged_data.apply(
                lambda row: extract_location(row['hostname'], row['deviceid']),
                axis=1
            )
        except Exception as e:
            log_message(f"âŒ HATA: location sÃ¼tunu oluÅŸturulurken hata: {e}")
            return

        if 'location' not in merged_data.columns:
            log_message("âŒ HATA: 'location' sÃ¼tunu merged_data iÃ§inde bulunamadÄ±!")
            return

        # ğŸ™ï¸ Åehir eÅŸleÅŸtirme iÅŸlemi
        station_mapping = station_info()
        if not station_mapping:
            log_message("âŒ ERROR: Station info mapping is empty! Check station-info.json")

        try:
            merged_data['city'] = merged_data['location'].map(lambda x: station_mapping.get(x, 'Unknown'))
        except Exception as e:
            log_message(f"âŒ HATA: 'city' sÃ¼tunu oluÅŸturulurken hata: {e}")
            return

        # ğŸ”¹ **Eksik UUIDâ€™leri Atama**
        newly_assigned_uuids = set()

        for index, row in merged_data.iterrows():
            deviceid = str(row["deviceid"])
            if deviceid not in uuid_mapping:
                if available_uuids:
                    assigned_uuid = available_uuids.pop(0)
                    uuid_mapping[deviceid] = assigned_uuid
                    newly_assigned_uuids.add(assigned_uuid)
                    log_message(f"ğŸ†• UUID atandÄ±: {deviceid} â†’ {assigned_uuid}")
                else:
                    assigned_uuid = "UUID_NOT_ASSIGNED"
                    log_message(f"âš ï¸ WARNING: UUID havuzunda boÅŸ UUID kalmadÄ±! {deviceid} iÃ§in UUID atamasÄ± yapÄ±lamadÄ±.")
                merged_data.at[index, 'uuid'] = assigned_uuid
            else:
                merged_data.at[index, 'uuid'] = uuid_mapping[deviceid]

        merged_data = filter_and_group_devices(merged_data)

        updated_devices = []
        new_devices = []

        for device in merged_data.to_dict(orient='records'):
            status_update = update_status_change(device, previous_data)

            updated_device = {
                "id": device["deviceid"],
                "deviceid": device["deviceid"],
                "hostname": device["hostname"],
                "ipaddress": device["ipaddress"],
                "ping_state": device["ping_state"],
                "serial": device.get("serial", ""),
                "model": device.get("model", ""),
                "device_type": determine_device_type(device.get("model", "")),
                "location": extract_location(device["hostname"], device["deviceid"]),
                "city": station_mapping.get(extract_location(device["hostname"], device["deviceid"]), "Unknown"),
                "uuid": device.get("uuid", "UNKNOWN"),
            }

            if status_update:
                updated_device.update(status_update)

            updated_devices.append(updated_device)

            if device["uuid"] == "UUID_NOT_ASSIGNED":
                log_message(f"âš ï¸ WARNING: {device['hostname']} iÃ§in UUID bulunamadÄ±!")

            if device["deviceid"] not in previous_data:
                new_devices.append(device)

        # âœ… JSON Ã§Ä±ktÄ±sÄ± kaydÄ±
        with open(json_file, 'w', encoding='utf-8') as f:
            json.dump(updated_devices, f, indent=2)

        log_message(f"ğŸŸ¢ LOG: {len(updated_devices)} cihaz verisi gÃ¼ncellendi â†’ {json_file}")

        # âœ… UUID dosyasÄ±nÄ± gÃ¼ncelle
        remaining_uuids = [uuid for uuid in available_uuids if uuid not in newly_assigned_uuids]
        uuid_data = {"deviceid_uuid_mapping": uuid_mapping, "available_uuids": remaining_uuids}
        uuid_file = 'D:/INTRANET/Netinfo/Data/UUID_Pool.json'
        with open(uuid_file, 'w', encoding='utf-8') as f:
            json.dump(uuid_data, f, indent=2)

        log_message(f"ğŸŸ¢ UUID verisi gÃ¼ncellendi â†’ {uuid_file}")

        log_message(f"Update complete. Checked {len(merged_data)} devices.")




if __name__ == "__main__":
    update_data()
